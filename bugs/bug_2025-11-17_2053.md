# Bug Report — Snapshot 2025-11-17_2053

Source artifacts:
- Database: `2025-11-17_2053/testing3.sqlite`
- Logs: `2025-11-17_2053/log.jsonl` and `full_log.jsonl`

## Open Issues

_Numbers preserve the original ordering so downstream references stay valid._

*(none — all bugs covered below are fixed in this snapshot)* 

## Fixed Issues

### 1. IOC order placement loses minutes to “invalid price” retries

**Summary**  
Every initial attempt to mirror the 3Commas base and safety buys fails with `Order has invalid price` because we send IOC limit orders that violate Hyperliquid’s tick size. The emitter forgets each work item and requeues it until it happens to retry with a rounded price, adding multi‑minute gaps where no hedge exists.

**Evidence**
```
2025-11-17T20:20:16.335679+01:00 WARN  could not place order
  {"hyperliquid":{"emitter":{"orderid":"0x00fd44fb8e406a627248b661c5c21086","error":"Order has invalid price.","action":{"Price":0.15332662,"OrderType":{"limit":{"tif":"Ioc"}}}}}}
2025-11-17T20:20:16.335738+01:00 DEBUG error submitting order, forgetting
  {"order-work":{"Identifier":{"OrderId":{"DealID":2386586210}}},"error":"could not place order: Order has invalid price."}
2025-11-17T20:20:18.754802+01:00 WARN  could not place order
  {"hyperliquid":{"emitter":{"orderid":"0x00fd44fb8e3fdcbf7248b6616214fbc4","error":"Order has invalid price.","action":{"Price":0.15337665,"OrderType":{"limit":{"tif":"Ioc"}}}}}}
2025-11-17T20:20:41.317699+01:00 INFO  Order sent
  {"hyperliquid":{"emitter":{"orderid":"0x00fd44fb8e406a627248b661c5c21086","action":{"Price":0.15345,"OrderType":{"limit":{"tif":"Ioc"}}},"requested_size":156,"hl_status":"filled"}}}
```

**Impact**  
Deals remain unhedged for ~15 s between retries and could drift much longer if volatility moves the spread between attempts. The noise also obscures genuine placement failures.

**Fix ideas**
1. Quantize IOC prices before hitting the API (use `hl.CoinConstraints.RoundPrice`).
2. Consider retrying immediately with the corrected price instead of forgetting the order.

_Status: fixed via `fix(emitter): quantize IOC prices before submitting` (be2adf0)._ 

### 2. Fill tracker spams cancels for orders Hyperliquid never saw

**Summary**  
The take‑profit clean‑up loop repeatedly cancelled cloid `0x00fd44fb8e3fdcbfeae18bf9587507a8` even though Hyperliquid responded “Order was never placed, already canceled, or filled. asset=173”. Because the tracker never marked the TP closed locally, every reconciliation pass kept emitting the same cancel and hammering the exchange with asset=173 errors.

**Evidence**
```
2025-11-17T20:22:10.90929+01:00 DEBUG updated order status
  {"filltracker":{"deal_id":2386549951,"orderid":"0x00fd44fb8e3fdcbfeae18bf9587507a8","status":"canceled"}}
2025-11-17T20:22:11.31246+01:00 WARN  could not cancel order
  {"hyperliquid":{"emitter":{"orderid":"0x00fd44fb8e3fdcbfeae18bf9587507a8","error":"Order was never placed, already canceled, or filled. asset=173"}}}
2025-11-17T20:22:11.312574+01:00 DEBUG error submitting order, forgetting
  {"order-work":{"Identifier":{"OrderId":{"DealID":2386549951}}},"error":"could not cancel order: Order was never placed, already canceled, or filled. asset=173"}
2025-11-17T20:22:12.922186+01:00 WARN  could not cancel order (repeats with same message)
```
- Associated work item had `BotEvent.RowID = 0`, proving we were cancelling a phantom TP.
- Reproduction captured in `TestReconcileTakeProfitsDropsCancelledTakeProfits`.

**Impact**  
Workers wasted capacity on impossible cancels, warning spam hid real failures, and restarts re-enqueued the phantom TP forever.

**Fix**  
`filltracker.Service` now zeroes the cached TP state as soon as a cancel request is emitted (or before recreating from scratch). Snapshots stop exposing those orders, so follow-up reconciliation runs no longer requeue cancels for orders Hyperliquid never saw.

_Status: fixed via `fix(filltracker): drop requeue of phantom TP cancels`._

### 3. Botevent inserts treat duplicates as WARN-level errors

**Summary**  
During every poll the engine re-reads historical 3Commas events, the storage layer logs thousands of WARNs `insert botevent log failed` / `insert botevent failed` with `sql: no rows in result set`. Nothing is actually wrong; the INSERT uses `ON CONFLICT DO NOTHING RETURNING id`, so duplicates yield `sql.ErrNoRows`, which the caller logs as a failure.

**Evidence**
```
2025-11-17T20:51:53.227712+01:00 WARN insert botevent log failed
  {"storage":{"RecordThreeCommasBotEventLog":{"order_id":"0x00fd44fb8e3f833c24b9d5f3633b0831","error":"sql: no rows in result set"}}}
2025-11-17T20:51:53.228214+01:00 WARN insert botevent failed
  {"storage":{"RecordThreeCommasBotEvent":{"order_id":"0x00fd44fb8e3f833ceae18bf953eb77c8","error":"sql: no rows in result set"}}}
2025-11-17T20:51:53.229116+01:00 WARN insert botevent log failed
  {"storage":{"RecordThreeCommasBotEventLog":{"order_id":"0x00fd44fb8e3f833c08e57bc68a4e9a27","error":"sql: no rows in result set"}}}
... (hundreds more identical WARNs until the poll completes)
```

**Impact**  
The WARN spam hides legitimate issues and makes log parsing useless during backfills.

**Fix ideas**
1. Teach `RecordThreeCommasBotEvent` / `RecordThreeCommasBotEventLog` to treat `sql.ErrNoRows` as “already inserted”.
2. Optionally downgrade duplicate detections to DEBUG so real storage faults stand out.

_Status: fixed via `fix(storage): do not log WARN for duplicate record` (b769a5b)._ 

### 4. Take-profit stack discovery always fails (wrong column)

**Summary**  
Order scaling tries to fetch the last nine take-profit legs but always logs `incomplete take profit stack: expected 9 legs, got 0`. The SQL filter compares `json_extract(payload,'$.OrderSize')` against the requested stack size. In the recorded payloads `OrderSize` is always zero—the actual leg quantity lives in `$.Size`—so the query never matches.

**Evidence**
```
2025-11-17T20:20:12.246063+01:00 DEBUG resolve stack sizes
  {"orderscaler":{"error":"incomplete take profit stack: expected 9 legs, got 0","deal_id":2386586210,"stack_size":9}}
2025-11-17T20:20:12.553809+01:00 DEBUG resolve stack sizes
  {"orderscaler":{"error":"incomplete take profit stack: expected 9 legs, got 0","deal_id":2386549951,"stack_size":9}}
2025-11-17T20:21:04.375807+01:00 DEBUG resolve stack sizes
  {"orderscaler":{"error":"incomplete take profit stack: expected 9 legs, got 0","deal_id":2386527036,"stack_size":9}}
```
`testing3.sqlite` query output:
```
sqlite> select botevent_id,json_extract(payload,'$.OrderSize'),json_extract(payload,'$.Size')
          from threecommas_botevents
          where order_id='0x00fd44fb8e3f833ceae18bf953eb77c8';
3940649977|0|155
3940649977|0|310
... (continues up to 1877)
```

**Impact**  
Scaler never sees the intended ladder, so it cannot distribute size deltas across the nine TP legs. Combined with the `scaled_orders` PK, this still causes repeated “duplicate scaled order” errors once we add per-leg multipliers.

**Fix ideas**
1. Update `ListLatestTakeProfitStackSizes` to filter on the column that actually represents the stack membership (likely `OrderPosition` only) and pull sizes from `$.Size`.
2. Add a unit test covering multi-leg TP stacks so regressions are caught.

_Status: fixed via `fix(storage): return latest take-profit stack sizes` (1d1ab03)._ 

### 5. Alias venue status rows still lack submissions

**Summary**  
`hyperliquid_status_history` records both `hyperliquid:testing` and `hyperliquid:default` updates for every order, but `hyperliquid_submissions` only stores create payloads for the primary venue (34 rows) plus a single alias cancel stub. There is no submission record for alias rows, so a rebuild cannot replay those orders.

**Evidence**
```
2025-11-17T20:20:13.39164+01:00 DEBUG OrderUpdates
  {"hyperliquid":{"ws":{"orders":[{"order":{"cloid":"0x00fd44fb8e406a62de5fd943ec133542"},"status":"open"}]}}}
2025-11-17T20:20:13.391978+01:00 DEBUG updated order status
  {"filltracker":{"venue":"hyperliquid:default","orderid":"0x00fd44fb8e406a62de5fd943ec133542","status":"open"}}
2025-11-17T20:20:13.392143+01:00 DEBUG status recorded
  {"storage":{"RecordHyperliquidStatus":{"ident":{"VenueID":"hyperliquid:default"}}}}
```
Database counts:
```
sqlite> select venue_id,count(*) from hyperliquid_submissions group by venue_id;
hyperliquid:testing|34
hyperliquid:default|1
sqlite> select venue_id,count(*) from hyperliquid_status_history group by venue_id;
hyperliquid:testing|74
hyperliquid:default|74
```

**Impact**  
After a restart we cannot reconstruct submission payloads for the alias venue, so any consumer watching `hyperliquid:default` will miss historic work and may drop events during a rebuild.

**Fix ideas**
1. When persisting a submission, duplicate the row for every venue ID we emit to (primary + alias) so FK relationships hold.
2. Backfill existing DBs by copying the primary payloads into alias rows before the next release.

_Status: fixed via `refactor: drop hyperliquid default alias` (73c2620)._ 

### 6. Modify payloads never persist

**Summary**  
`hyperliquid_submissions` only shows `action_kind='create'` (34 rows) and a single cancel despite orders being modified (e.g., TP cloid `0x00fd44fb8e3f833ceae18bf953eb77c8` reaches 1 877 DOGE). There are no `modify_payloads`, so the DB still believes every order sits at its original create size.

**Evidence**
```
sqlite> select action_kind,count(*) from hyperliquid_submissions group by action_kind;
cancel|1
create|34
sqlite> select order_id,scaled_size from scaled_orders where order_id like '0x00fd44fb8e3f833ceae18bf953eb77c8%';
0x00fd44fb8e3f833ceae18bf953eb77c8#0|1877.0
```

**Impact**  
On restart we would replay the stale create payloads and reissue orders at their old sizes, undoing legitimate modifications or creating duplicates.

**Fix ideas**
1. Ensure every successful `Modify` call updates the `hyperliquid_submissions` row (or appends to `modify_payloads`) for both venues.
2. When a modify attempt “fails” due to missing `response.data`, immediately reconcile via websocket/status snapshot to decide whether to persist anyway.

_Status: fixed via `fix(tp-scaling): persist TP modifies and unblock e2e` (b7a1ecf)._ 
